[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m a computational physicist and R&D scientist working on data-driven materials discovery and electrochemical sensors. This blog is my open notebook — translating between equations, features, and materials.\nTopics you’ll see here: - Physics-informed feature engineering - SHAP and interpretability for scientists - Graph features for crystal structures - Common pitfalls (correlation ≠ causation, extrapolation, leakage)"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "All Posts",
    "section": "",
    "text": "Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nAuthor\n\n\n\n\n\n\n\n\nNov 13, 2025\n\n\nWhat ML Sees in Crystal Graphs\n\n\n \n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/01_graph_features_in_materials.html",
    "href": "posts/01_graph_features_in_materials.html",
    "title": "What ML Sees in Crystal Graphs",
    "section": "",
    "text": "Can topology alone (without chemistry) tell us anything about formation energy?\nMostly all of the machine learning/ Deep learning algorithms used to predict materials properties like formation energy, band gap are trained on same set of dataset. On every models the dataset overlaps. Mostly the difference in these models are the way we extract features, mostly it combines atomic and geometric properties. In this short experiment, I tried to convert few structures (1000) from materials project datasets into graphs. These are the subset of data used to train MEGNET model. In this experiment atoms acts as node and edges are the constructed between neighbors within 4 Å distance from the node.\nFor example the graph structure for material with mp-1103373 (KSn2) looks like this: !\nFrom each graph I extracted:\nThe extracted features heatmap shows how simple graph - based structural features relate to formation energy (eV/atom) !\nThen I trained simple regressors (RandomForest, GradientBoosting, etc.) on these 6 features to predict formation energy per atom."
  },
  {
    "objectID": "posts/01_graph_features_in_materials.html#training-simple-randomforestregressor-as-an-example",
    "href": "posts/01_graph_features_in_materials.html#training-simple-randomforestregressor-as-an-example",
    "title": "What ML Sees in Crystal Graphs",
    "section": "Training simple RandomForestRegressor as an example",
    "text": "Training simple RandomForestRegressor as an example\n\nfrom pathlib import Path\nimport joblib\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, r2_score\nfrom sklearn.model_selection import train_test_split\n\nFEATURES_CSV = \"../mp2019_graph_features.csv\"\nMODEL_PATH = \"../rf_graph_energy_model.joblib\"\n\ndef main():\n    #load feature dataset\n    df = pd.read_csv(FEATURES_CSV)\n    feature_cols = [\n        \"n_nodes\",\n        \"n_edges\",\n        \"avg_degree\",\n        \"std_degree\",\n        \"avg_clustering\",\n        \"density\",\n    ]\n\n    X = df[feature_cols].values\n    y = df[\"energy_pa\"].values\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.1, random_state=42\n    )\n\n    print(f\"Training simple RandomForestRegressor\")\n\n    model = RandomForestRegressor(\n        n_estimators=300,\n        max_depth=None,\n        random_state=42,\n        n_jobs=-1,\n    )\n    model.fit(X_train, y_train)\n\n    y_pred = model.predict(X_test)\n    #get MAE\n    mae = mean_absolute_error(y_test, y_pred)\n    #Get R2\n    r2 = r2_score(y_test, y_pred)\n\n    print(\"\\n Performance (graph features to formation energy):\")\n    print(f\"  MAE: {mae:.4f} eV/atom\")\n    print(f\"  R² : {r2:.4f}\")\n\nif __name__ == \"__main__\":\n    main()\n\nTraining simple RandomForestRegressor\n\n Performance (graph features to formation energy):\n  MAE: 0.7109 eV/atom\n  R² : 0.2156\n\n\n\nsimple Interpretation\n\nNo chemical information included\nOnly graph based features are used\nsmall amount of dataset is used for the experiment\nWithout chemical information encoded the model cannot differentiate many important information such as metal vs semiconductor, ionic vs covalent bonding, oxidation states, bond strengths, etc., which plays major role in prediction task\nIn this test example MAE of around 0.7 eV is completely expected and make sense\nR2 indicates that nearly 21% of the variance in formation energy is captured with topology only, somehow interesting\n\n\n\nConclusion\n\nEven without explicit chemistry, topology contains weak but real signals about stability. The fun begins when we add chemistry and distance-weighted edges** — stay tuned."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ML in Physics — Blog",
    "section": "",
    "text": "Welcome! I’m building bridges between machine learning features and physical intuition.\n\nShort, focused posts (600–1000 words)\nClear code snippets you can run\nVisuals that connect features to physics\n\nStart with the first post: What ML Sees in Crystal Graphs."
  }
]